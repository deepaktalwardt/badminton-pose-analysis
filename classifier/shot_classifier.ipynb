{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up CNN for classifying badminton shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['backhand', 'defense', 'drop', 'smash']\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Conv2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras import callbacks\n",
    "\n",
    "PATH = os.getcwd()\n",
    "data_path = './data/'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "print(data_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: backhand\n",
      "Images found: 133\n",
      "Loading the images of dataset-backhand\n",
      "\n",
      "Frames processed: 10 in backhand\n",
      "Frames processed: 20 in backhand\n",
      "Frames processed: 30 in backhand\n",
      "Frames processed: 40 in backhand\n",
      "Frames processed: 50 in backhand\n",
      "Frames processed: 60 in backhand\n",
      "Frames processed: 70 in backhand\n",
      "Frames processed: 80 in backhand\n",
      "Frames processed: 90 in backhand\n",
      "Frames processed: 100 in backhand\n",
      "Frames processed: 110 in backhand\n",
      "Frames processed: 120 in backhand\n",
      "Frames processed: 130 in backhand\n",
      "Class: defense\n",
      "Images found: 186\n",
      "Loading the images of dataset-defense\n",
      "\n",
      "Frames processed: 10 in defense\n",
      "Frames processed: 20 in defense\n",
      "Frames processed: 30 in defense\n",
      "Frames processed: 40 in defense\n",
      "Frames processed: 50 in defense\n",
      "Frames processed: 60 in defense\n",
      "Frames processed: 70 in defense\n",
      "Frames processed: 80 in defense\n",
      "Frames processed: 90 in defense\n",
      "Frames processed: 100 in defense\n",
      "Frames processed: 110 in defense\n",
      "Frames processed: 120 in defense\n",
      "Frames processed: 130 in defense\n",
      "Frames processed: 140 in defense\n",
      "Frames processed: 150 in defense\n",
      "Frames processed: 160 in defense\n",
      "Frames processed: 170 in defense\n",
      "Frames processed: 180 in defense\n",
      "Class: drop\n",
      "Images found: 483\n",
      "Loading the images of dataset-drop\n",
      "\n",
      "Frames processed: 10 in drop\n",
      "Frames processed: 20 in drop\n",
      "Frames processed: 30 in drop\n",
      "Frames processed: 40 in drop\n",
      "Frames processed: 50 in drop\n",
      "Frames processed: 60 in drop\n",
      "Frames processed: 70 in drop\n",
      "Frames processed: 80 in drop\n",
      "Frames processed: 90 in drop\n",
      "Frames processed: 100 in drop\n",
      "Frames processed: 110 in drop\n",
      "Frames processed: 120 in drop\n",
      "Frames processed: 130 in drop\n",
      "Frames processed: 140 in drop\n",
      "Frames processed: 150 in drop\n",
      "Frames processed: 160 in drop\n",
      "Frames processed: 170 in drop\n",
      "Frames processed: 180 in drop\n",
      "Frames processed: 190 in drop\n",
      "Frames processed: 200 in drop\n",
      "Frames processed: 210 in drop\n",
      "Frames processed: 220 in drop\n",
      "Frames processed: 230 in drop\n",
      "Frames processed: 240 in drop\n",
      "Frames processed: 250 in drop\n",
      "Frames processed: 260 in drop\n",
      "Frames processed: 270 in drop\n",
      "Frames processed: 280 in drop\n",
      "Frames processed: 290 in drop\n",
      "Frames processed: 300 in drop\n",
      "Frames processed: 310 in drop\n",
      "Frames processed: 320 in drop\n",
      "Frames processed: 330 in drop\n",
      "Frames processed: 340 in drop\n",
      "Frames processed: 350 in drop\n",
      "Frames processed: 360 in drop\n",
      "Frames processed: 370 in drop\n",
      "Frames processed: 380 in drop\n",
      "Frames processed: 390 in drop\n",
      "Frames processed: 400 in drop\n",
      "Frames processed: 410 in drop\n",
      "Frames processed: 420 in drop\n",
      "Frames processed: 430 in drop\n",
      "Frames processed: 440 in drop\n",
      "Frames processed: 450 in drop\n",
      "Frames processed: 460 in drop\n",
      "Frames processed: 470 in drop\n",
      "Frames processed: 480 in drop\n",
      "Class: smash\n",
      "Images found: 360\n",
      "Loading the images of dataset-smash\n",
      "\n",
      "Frames processed: 10 in smash\n",
      "Frames processed: 20 in smash\n",
      "Frames processed: 30 in smash\n",
      "Frames processed: 40 in smash\n",
      "Frames processed: 50 in smash\n",
      "Frames processed: 60 in smash\n",
      "Frames processed: 70 in smash\n",
      "Frames processed: 80 in smash\n",
      "Frames processed: 90 in smash\n",
      "Frames processed: 100 in smash\n",
      "Frames processed: 110 in smash\n",
      "Frames processed: 120 in smash\n",
      "Frames processed: 130 in smash\n",
      "Frames processed: 140 in smash\n",
      "Frames processed: 150 in smash\n",
      "Frames processed: 160 in smash\n",
      "Frames processed: 170 in smash\n",
      "Frames processed: 180 in smash\n",
      "Frames processed: 190 in smash\n",
      "Frames processed: 200 in smash\n",
      "Frames processed: 210 in smash\n",
      "Frames processed: 220 in smash\n",
      "Frames processed: 230 in smash\n",
      "Frames processed: 240 in smash\n",
      "Frames processed: 250 in smash\n",
      "Frames processed: 260 in smash\n",
      "Frames processed: 270 in smash\n",
      "Frames processed: 280 in smash\n",
      "Frames processed: 290 in smash\n",
      "Frames processed: 300 in smash\n",
      "Frames processed: 310 in smash\n",
      "Frames processed: 320 in smash\n",
      "Frames processed: 330 in smash\n",
      "Frames processed: 340 in smash\n",
      "Frames processed: 350 in smash\n",
      "Frames processed: 360 in smash\n"
     ]
    }
   ],
   "source": [
    "# Processing input dataset\n",
    "img_rows = 128\n",
    "img_cols = 128\n",
    "num_channel = 1\n",
    "num_epoch = 20\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 4\n",
    "labels_name = {'smash':0,'drop':1,'defense':2,'backhand':3}\n",
    "\n",
    "img_data_list = []\n",
    "labels_list = []\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list = os.listdir(data_path + '/' + dataset)\n",
    "    print(\"Class: \" + dataset)\n",
    "    print(\"Images found: \" + str(len(img_list)))\n",
    "    print ('Loading the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    label = labels_name[dataset]\n",
    "    counter = 0\n",
    "    for img in img_list:\n",
    "        input_img = cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "        input_img_resize = cv2.resize(input_img,(img_rows, img_cols))\n",
    "        img_data_list.append(input_img_resize)\n",
    "        labels_list.append(label)\n",
    "        counter += 1\n",
    "        if counter % 10 == 0:\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"Frames processed: \" + str(counter) + \" in \" + dataset)\n",
    "#             cv2.imshow(\"Frame: \" + img, input_img_resize)\n",
    "#             cv2.waitKey(500)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1162\n",
      "1162\n",
      "(1162, 128, 128)\n",
      "(array([0, 1, 2, 3]), array([360, 483, 186, 133], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(len(img_data_list))\n",
    "print(len(labels_list))\n",
    "\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "print (img_data.shape)\n",
    "\n",
    "labels = np.array(labels_list)\n",
    "\n",
    "# print the count of number of samples for different classes\n",
    "print(np.unique(labels,return_counts=True))\n",
    "\n",
    "# convert class labels to on-hot encoding\n",
    "Y = np_utils.to_categorical(labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swlee\\Anaconda3\\envs\\cmpe257_project\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "img_data = np.expand_dims(img_data, axis=4) \n",
    "print (img_data.shape)\n",
    "\n",
    "# Shuffle the dataset\n",
    "x, y = shuffle(img_data,Y, random_state=2)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\swlee\\Anaconda3\\envs\\cmpe257_project\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\swlee\\Anaconda3\\envs\\cmpe257_project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "input_shape = img_data[0].shape\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3), padding='same', input_shape=input_shape, activation='relu'))\n",
    "model.add(Conv2D(32,(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64,(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128,(3,3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(128,(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(256,(3,3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(256,(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.0001), metrics=['accuracy'])\n",
    "\n",
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape = input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Convolution2D(64, 3, 3))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=[\"accuracy\"])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=[\"accuracy\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\n",
    "model.layers[0].output_shape\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\swlee\\Anaconda3\\envs\\cmpe257_project\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swlee\\Anaconda3\\envs\\cmpe257_project\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 929 samples, validate on 233 samples\n",
      "Epoch 1/20\n",
      "929/929 [==============================] - 9s 10ms/step - loss: 1.3135 - acc: 0.4650 - val_loss: 1.0939 - val_acc: 0.6309\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.09393, saving model to Best-weights-cnn-1-001-1.3135-0.4650.hdf5\n",
      "Epoch 2/20\n",
      "929/929 [==============================] - 5s 6ms/step - loss: 0.8005 - acc: 0.7169 - val_loss: 0.4233 - val_acc: 0.8755\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.09393 to 0.42330, saving model to Best-weights-cnn-1-002-0.8005-0.7169.hdf5\n",
      "Epoch 3/20\n",
      "929/929 [==============================] - 5s 6ms/step - loss: 0.5280 - acc: 0.8299 - val_loss: 0.3321 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.42330 to 0.33207, saving model to Best-weights-cnn-1-003-0.5280-0.8299.hdf5\n",
      "Epoch 4/20\n",
      "929/929 [==============================] - 5s 6ms/step - loss: 0.5130 - acc: 0.8439 - val_loss: 0.5187 - val_acc: 0.8927\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.33207\n",
      "Epoch 5/20\n",
      "929/929 [==============================] - 5s 6ms/step - loss: 0.4302 - acc: 0.8762 - val_loss: 0.2932 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.33207 to 0.29319, saving model to Best-weights-cnn-1-005-0.4302-0.8762.hdf5\n",
      "Epoch 6/20\n",
      "929/929 [==============================] - 5s 6ms/step - loss: 0.3820 - acc: 0.8762 - val_loss: 0.2843 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.29319 to 0.28429, saving model to Best-weights-cnn-1-006-0.3820-0.8762.hdf5\n",
      "Epoch 7/20\n",
      "929/929 [==============================] - 5s 6ms/step - loss: 0.3621 - acc: 0.8945 - val_loss: 0.3011 - val_acc: 0.9142\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28429\n",
      "Epoch 8/20\n",
      "929/929 [==============================] - 5s 6ms/step - loss: 0.3393 - acc: 0.9117 - val_loss: 0.3046 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28429\n",
      "Epoch 9/20\n",
      "929/929 [==============================] - 5s 6ms/step - loss: 0.2848 - acc: 0.9268 - val_loss: 0.2521 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.28429 to 0.25206, saving model to Best-weights-cnn-1-009-0.2848-0.9268.hdf5\n",
      "Epoch 10/20\n",
      "929/929 [==============================] - 5s 6ms/step - loss: 0.2798 - acc: 0.9139 - val_loss: 0.2408 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.25206 to 0.24079, saving model to Best-weights-cnn-1-010-0.2798-0.9139.hdf5\n",
      "Epoch 11/20\n",
      "929/929 [==============================] - 5s 6ms/step - loss: 0.2837 - acc: 0.9128 - val_loss: 0.2981 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.24079\n",
      "Epoch 12/20\n",
      "929/929 [==============================] - 5s 6ms/step - loss: 0.2868 - acc: 0.9236 - val_loss: 0.2822 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.24079\n",
      "Epoch 13/20\n",
      "929/929 [==============================] - 5s 6ms/step - loss: 0.2409 - acc: 0.9354 - val_loss: 0.2768 - val_acc: 0.9099acc: 0\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.24079\n"
     ]
    }
   ],
   "source": [
    "filename='model_train_new.csv'\n",
    "csv_log = callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "\n",
    "early_stopping=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='min')\n",
    "\n",
    "filepath = \"Best-weights-cnn-1-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [csv_log, early_stopping, checkpoint]\n",
    "\n",
    "hist = model.fit(X_train, y_train, batch_size=4, nb_epoch=num_epoch, verbose=1, validation_data=(X_test, y_test),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 [==============================] - 0s 2ms/step\n",
      "Test Loss: 0.2767593262661168\n",
      "Test accuracy: 0.9098712446351931\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x=X_test, y=y_test, verbose=1)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file saved_model already exists.\n",
      "Error occurred while processing: saved_model.\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/shot_classifier_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                3686464   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 3,714,788\n",
      "Trainable params: 3,714,788\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "#new_model = Model()\n",
    "new_model = load_model('saved_model/shot_classifier_2')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test[:1]\n",
    "new_model.predict_classes(X_test, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233, 128, 128, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
